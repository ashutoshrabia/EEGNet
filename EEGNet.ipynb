{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OcRhOpYen3smIkllJWbZtqyGnN1sV0hX",
      "authorship_tag": "ABX9TyPtgKugN88pM37FFlPFLZTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashutoshrabia/EEGNet/blob/main/EEGNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "-O7WylZcpYfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwOVQ3QM1e6J"
      },
      "outputs": [],
      "source": [
        "import numpy as np                                      # for dealing with data\n",
        "from scipy.signal import butter, sosfiltfilt, sosfreqz  # for filtering\n",
        "import matplotlib.pyplot as plt                         # for plotting\n",
        "import pandas\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create filtering variables\n",
        "fs = 200.0     # 200 Hz sampling rate\n",
        "lowcut = 1.0   # 0.1 Hz is the lowest frequency we will pass\n",
        "highcut = 40.0 # 30  Hz is the highest frequency we will pass."
      ],
      "metadata": {
        "id": "owX1OJjt1pZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def butter_bandpass_filter(raw_data, fs, lowcut = 1.0, highcut =40.0, order = 5):\n",
        "    '''\n",
        "    The filter I want to apply to my raw eeg data.\n",
        "    :raw_data (nparray): data you want to process\n",
        "    :fs (float): sampling rate\n",
        "    :lowcut (float, optional): lowest frequency we will pass\n",
        "    :highcut (float, optional): highest frequency we will pass\n",
        "    :order (int, optional): order of filter\n",
        "    '''\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
        "    filted_data = sosfiltfilt(sos, raw_data)\n",
        "    return filted_data"
      ],
      "metadata": {
        "id": "i7GIiAlY1s3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_s = 0      # epoch starting time relative to stmulus in miliseconds\n",
        "epoch_e = 700    # epoch ending time relative to stmulus in miliseconds\n",
        "bl_s = 0         # baseline starting time relative to stmulus in miliseconds\n",
        "bl_e = 100       # baseline ending time relative to stmulus in miliseconds\n",
        "\n",
        "\n",
        "# number of mark per epoch\n",
        "epoch_len = int((abs(epoch_s) + abs(epoch_e)) * (fs / 1000))"
      ],
      "metadata": {
        "id": "QJQBHZaL1ulg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subj_num = 16\n",
        "test_subj_num = 10\n",
        "stimulus_per_subj = 340\n",
        "trial_per_subj = 5\n",
        "\n",
        "channels = ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1',\n",
        "    'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz',\n",
        "    'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2',\n",
        "    'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
        "    'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
        "    'PO7', 'POz', 'P08', 'O1', 'O2']"
      ],
      "metadata": {
        "id": "-1TvNmkx1wvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_labels = pd.read_csv('/content/drive/MyDrive/TrainLabels.csv')\n",
        "sample_train_data = pd.read_csv('/content/drive/MyDrive/Data_S02_Sess01.csv')"
      ],
      "metadata": {
        "id": "EuNxwZn41zwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "M9d017CN2PPs",
        "outputId": "6ad149c8-710d-401d-bcbb-501e5e5b9db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            IdFeedBack  Prediction\n",
              "0     S02_Sess01_FB001           1\n",
              "1     S02_Sess01_FB002           1\n",
              "2     S02_Sess01_FB003           0\n",
              "3     S02_Sess01_FB004           0\n",
              "4     S02_Sess01_FB005           1\n",
              "...                ...         ...\n",
              "5435  S26_Sess05_FB096           1\n",
              "5436  S26_Sess05_FB097           0\n",
              "5437  S26_Sess05_FB098           0\n",
              "5438  S26_Sess05_FB099           0\n",
              "5439  S26_Sess05_FB100           1\n",
              "\n",
              "[5440 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f719b2f0-8e5b-4050-90ec-82c2396feefe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IdFeedBack</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S02_Sess01_FB001</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S02_Sess01_FB002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S02_Sess01_FB003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S02_Sess01_FB004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S02_Sess01_FB005</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5435</th>\n",
              "      <td>S26_Sess05_FB096</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5436</th>\n",
              "      <td>S26_Sess05_FB097</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5437</th>\n",
              "      <td>S26_Sess05_FB098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5438</th>\n",
              "      <td>S26_Sess05_FB099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5439</th>\n",
              "      <td>S26_Sess05_FB100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5440 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f719b2f0-8e5b-4050-90ec-82c2396feefe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f719b2f0-8e5b-4050-90ec-82c2396feefe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f719b2f0-8e5b-4050-90ec-82c2396feefe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0214bbc1-c957-4b0d-af28-3416e21ff3c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0214bbc1-c957-4b0d-af28-3416e21ff3c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0214bbc1-c957-4b0d-af28-3416e21ff3c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_55867fd4-934b-4872-8ea9-7fab2c6f552d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_labels')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_55867fd4-934b-4872-8ea9-7fab2c6f552d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_labels');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_labels",
              "summary": "{\n  \"name\": \"train_labels\",\n  \"rows\": 5440,\n  \"fields\": [\n    {\n      \"column\": \"IdFeedBack\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5440,\n        \"samples\": [\n          \"S11_Sess03_FB047\",\n          \"S24_Sess01_FB003\",\n          \"S06_Sess02_FB011\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_list = np.load('/content/drive/MyDrive/train_data.npy')\n",
        "test_data_list = np.load('/content/drive/MyDrive/test_data.npy')\n",
        "print('Epoched training data shape: ' + str(train_data_list.shape))\n",
        "print('Epoched testing data shape: ' + str(test_data_list.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n7SZfCb3AkB",
        "outputId": "e9feeb35-9377-4fc8-df2d-7ab481f4452e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoched training data shape: (16, 340, 56, 140)\n",
            "Epoched testing data shape: (10, 340, 56, 140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SpatialDropout2D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Input, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "g4jQmznL50aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEGNet\n"
      ],
      "metadata": {
        "id": "B_QrI78u8d48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EEGNet(nb_classes, Chans = 64, Samples = 128,dropoutRate = 0.5, kernLength = 64, F1 = 8,D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
        "    if dropoutType == 'SpatialDropout2D':\n",
        "        dropoutType = SpatialDropout2D\n",
        "    elif dropoutType == 'Dropout':\n",
        "        dropoutType = Dropout\n",
        "    else:\n",
        "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                         'or Dropout, passed as a string.')\n",
        "\n",
        "    input1   = Input(shape = (1, Chans, Samples))\n",
        "\n",
        "\n",
        "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
        "                                   input_shape = (1, Chans, Samples),\n",
        "                                   use_bias = False)(input1)\n",
        "    block1       = BatchNormalization(axis = 1)(block1)\n",
        "    block1       = DepthwiseConv2D((1, D), use_bias = False,\n",
        "                                   depth_multiplier = D,\n",
        "                                   depthwise_constraint = max_norm(1.),\n",
        "                                  data_format='channels_last')(block1)\n",
        "    block1       = BatchNormalization(axis = 1)(block1)\n",
        "    block1       = Activation('elu')(block1)\n",
        "    block1       = AveragePooling2D((1, 4), data_format='channels_last')(block1)\n",
        "    block1       = dropoutType(dropoutRate)(block1)\n",
        "\n",
        "    block2       = SeparableConv2D(F2, (1, 16),\n",
        "                                   use_bias = False, padding = 'same')(block1)\n",
        "    block2       = BatchNormalization(axis = 1)(block2)\n",
        "    block2       = Activation('elu')(block2)\n",
        "    block2       = AveragePooling2D((1, 8), data_format='channels_last')(block2)\n",
        "    block2       = dropoutType(dropoutRate)(block2)\n",
        "\n",
        "    flatten      = Flatten(name = 'flatten')(block2)\n",
        "\n",
        "    dense        = Dense(nb_classes, name = 'dense',\n",
        "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "\n",
        "    return Model(inputs=input1, outputs=softmax)"
      ],
      "metadata": {
        "id": "LEbqYN369IUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the appropriate dimensions based on the total number of elements\n",
        "total_elements1 = train_data_list.size\n",
        "num_samples1 = 16 * 340\n",
        "channels1 = 56\n",
        "time_points1 = total_elements1 // (num_samples1 * channels1)\n",
        "\n",
        "# Reshape the array with the calculated dimensions\n",
        "X_train_valid = np.reshape(train_data_list, (num_samples1, channels1, time_points1))\n",
        "print('Shape of X_train_valid:', X_train_valid.shape)\n",
        "# Calculate the appropriate dimensions based on the total number of elements\n",
        "total_elements2 = test_data_list.size\n",
        "num_samples2 = 10 * 340\n",
        "channels2 = 56\n",
        "time_points2 = total_elements2 // (num_samples2 * channels2)\n",
        "\n",
        "# Reshape the array with the calculated dimensions\n",
        "X_test = np.reshape(test_data_list, (num_samples2, channels2, time_points2))\n",
        "print('Shape of X_test_valid:', X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAb4T2G0o4fz",
        "outputId": "ef8dd035-e774-4a75-d2bb-16a9d8c05407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_valid: (5440, 56, 140)\n",
            "Shape of X_test_valid: (3400, 56, 140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train_valid = np.reshape(train_data_list, (16*340, 56, 260))\n",
        "Y_train_valid = pd.read_csv('/content/drive/MyDrive/TrainLabels.csv')['Prediction'].values\n",
        "X_train = X_train_valid[1360:, :]\n",
        "X_valid = X_train_valid[:1360, :]\n",
        "y_train = Y_train_valid[1360:]\n",
        "y_valid = Y_train_valid[:1360]\n",
        "\n",
        "kernels, chans, samples = 1, 56, 140\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], kernels, chans, samples)\n",
        "X_test = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "print(str(X_train.shape[0]) + ' train samples')\n",
        "print(str(X_valid.shape[0]) + ' validation samples')\n",
        "print(str(X_test.shape[0]) + ' test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwQmnMennKvD",
        "outputId": "aa9bf269-179f-4da0-87ac-4267c2e5e644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4080 train samples\n",
            "1360 validation samples\n",
            "3400 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "fgKg1bKp8kZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EEGNet(nb_classes=2, Chans=chans, Samples=samples,\n",
        "               dropoutRate=0.5, kernLength=100, F1=8, D=2, F2=16,\n",
        "               dropoutType='Dropout')\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "numParams = model.count_params()\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n"
      ],
      "metadata": {
        "id": "h8eAkkcNoCIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_0 = 1/(len([y for y in Y_train_valid if y == 0]))\n",
        "weight_1 = 1/(len([y for y in Y_train_valid if y == 1]))\n",
        "class_weights = {0: weight_0, 1: weight_1}\n",
        "\n",
        "fittedModel = model.fit(X_train, y_train, batch_size=34, epochs=100,verbose=2, validation_data=(X_valid, y_valid),callbacks=[checkpointer], class_weight=class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKKcgRCpoPOK",
        "outputId": "e64027a3-e452-4c49-8ead-6329af9efff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 840510144276900229383898578026496.00000, saving model to /tmp/checkpoint.h5\n",
            "120/120 - 17s - loss: 2.5690e-04 - accuracy: 0.5162 - val_loss: 840510144276900229383898578026496.0000 - val_accuracy: 0.6096 - 17s/epoch - 138ms/step\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 840510144276900229383898578026496.00000 to 18784282596770288991469568.00000, saving model to /tmp/checkpoint.h5\n",
            "120/120 - 14s - loss: 2.4831e-04 - accuracy: 0.5618 - val_loss: 18784282596770288991469568.0000 - val_accuracy: 0.7088 - 14s/epoch - 120ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss did not improve from 18784282596770288991469568.00000\n",
            "120/120 - 14s - loss: 2.4347e-04 - accuracy: 0.6034 - val_loss: nan - val_accuracy: 0.4382 - 14s/epoch - 114ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 18784282596770288991469568.00000\n",
            "120/120 - 13s - loss: 2.4120e-04 - accuracy: 0.6147 - val_loss: 2502434285314323331449316442112.0000 - val_accuracy: 0.7640 - 13s/epoch - 110ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 18784282596770288991469568.00000\n",
            "120/120 - 14s - loss: 2.3860e-04 - accuracy: 0.6208 - val_loss: nan - val_accuracy: 0.6890 - 14s/epoch - 115ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 18784282596770288991469568.00000 to 83753235104626255069184.00000, saving model to /tmp/checkpoint.h5\n",
            "120/120 - 14s - loss: 2.3848e-04 - accuracy: 0.6132 - val_loss: 83753235104626255069184.0000 - val_accuracy: 0.7125 - 14s/epoch - 120ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.3524e-04 - accuracy: 0.6238 - val_loss: 252030024412862277169971200.0000 - val_accuracy: 0.7632 - 14s/epoch - 114ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.3499e-04 - accuracy: 0.6392 - val_loss: 4607989104381540436505167659008.0000 - val_accuracy: 0.7824 - 13s/epoch - 105ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.3328e-04 - accuracy: 0.6248 - val_loss: nan - val_accuracy: 0.6574 - 13s/epoch - 107ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.3273e-04 - accuracy: 0.6397 - val_loss: nan - val_accuracy: 0.6074 - 14s/epoch - 114ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.3281e-04 - accuracy: 0.6270 - val_loss: nan - val_accuracy: 0.4588 - 14s/epoch - 117ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.3303e-04 - accuracy: 0.6358 - val_loss: nan - val_accuracy: 0.6897 - 14s/epoch - 117ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2988e-04 - accuracy: 0.6370 - val_loss: nan - val_accuracy: 0.5272 - 14s/epoch - 114ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.3098e-04 - accuracy: 0.6265 - val_loss: nan - val_accuracy: 0.7250 - 14s/epoch - 118ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2816e-04 - accuracy: 0.6461 - val_loss: nan - val_accuracy: 0.2147 - 13s/epoch - 106ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2890e-04 - accuracy: 0.6480 - val_loss: nan - val_accuracy: 0.2147 - 13s/epoch - 104ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2834e-04 - accuracy: 0.6488 - val_loss: 2847252186836060349225786522206208.0000 - val_accuracy: 0.6801 - 14s/epoch - 115ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2921e-04 - accuracy: 0.6466 - val_loss: nan - val_accuracy: 0.6338 - 14s/epoch - 113ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2541e-04 - accuracy: 0.6593 - val_loss: 745720527220959466500541906944.0000 - val_accuracy: 0.7206 - 14s/epoch - 114ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2955e-04 - accuracy: 0.6429 - val_loss: nan - val_accuracy: 0.6265 - 13s/epoch - 112ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2549e-04 - accuracy: 0.6507 - val_loss: nan - val_accuracy: 0.5603 - 14s/epoch - 115ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2338e-04 - accuracy: 0.6483 - val_loss: 7131949258387398814339170304.0000 - val_accuracy: 0.7022 - 13s/epoch - 105ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2555e-04 - accuracy: 0.6654 - val_loss: nan - val_accuracy: 0.5316 - 13s/epoch - 107ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2470e-04 - accuracy: 0.6434 - val_loss: nan - val_accuracy: 0.5044 - 13s/epoch - 112ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.2418e-04 - accuracy: 0.6564 - val_loss: nan - val_accuracy: 0.2147 - 14s/epoch - 116ms/step\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.2249e-04 - accuracy: 0.6689 - val_loss: 381376428209959399600003481600.0000 - val_accuracy: 0.7471 - 13s/epoch - 111ms/step\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 15s - loss: 2.2016e-04 - accuracy: 0.6689 - val_loss: 442228469150139386903275153391616.0000 - val_accuracy: 0.7551 - 15s/epoch - 121ms/step\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1941e-04 - accuracy: 0.6701 - val_loss: nan - val_accuracy: 0.7316 - 14s/epoch - 115ms/step\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 15s - loss: 2.2067e-04 - accuracy: 0.6699 - val_loss: 1820761363532863578081209614336.0000 - val_accuracy: 0.7331 - 15s/epoch - 122ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.1946e-04 - accuracy: 0.6745 - val_loss: 11564816966982824015266054144.0000 - val_accuracy: 0.6875 - 13s/epoch - 108ms/step\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1901e-04 - accuracy: 0.6647 - val_loss: nan - val_accuracy: 0.3221 - 14s/epoch - 113ms/step\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 32: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1888e-04 - accuracy: 0.6635 - val_loss: nan - val_accuracy: 0.6382 - 14s/epoch - 116ms/step\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.1666e-04 - accuracy: 0.6762 - val_loss: nan - val_accuracy: 0.6772 - 13s/epoch - 112ms/step\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1565e-04 - accuracy: 0.6752 - val_loss: nan - val_accuracy: 0.4691 - 14s/epoch - 117ms/step\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1427e-04 - accuracy: 0.6846 - val_loss: 6257990602588202354631010942976.0000 - val_accuracy: 0.7632 - 14s/epoch - 119ms/step\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 36: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1523e-04 - accuracy: 0.6745 - val_loss: nan - val_accuracy: 0.7132 - 14s/epoch - 113ms/step\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 37: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.1403e-04 - accuracy: 0.6777 - val_loss: nan - val_accuracy: 0.5456 - 13s/epoch - 108ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 38: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 12s - loss: 2.1152e-04 - accuracy: 0.6850 - val_loss: nan - val_accuracy: 0.4890 - 12s/epoch - 103ms/step\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 39: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1096e-04 - accuracy: 0.6863 - val_loss: nan - val_accuracy: 0.2147 - 14s/epoch - 115ms/step\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.1140e-04 - accuracy: 0.6963 - val_loss: nan - val_accuracy: 0.7088 - 13s/epoch - 110ms/step\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 41: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.1117e-04 - accuracy: 0.6902 - val_loss: nan - val_accuracy: 0.6176 - 14s/epoch - 117ms/step\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 42: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.0960e-04 - accuracy: 0.6931 - val_loss: nan - val_accuracy: 0.6625 - 14s/epoch - 117ms/step\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.0720e-04 - accuracy: 0.7074 - val_loss: 107164313140641126480657514496.0000 - val_accuracy: 0.7390 - 14s/epoch - 113ms/step\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 44: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.0296e-04 - accuracy: 0.7064 - val_loss: 1584771146566736984414355456.0000 - val_accuracy: 0.7551 - 13s/epoch - 110ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.0465e-04 - accuracy: 0.7037 - val_loss: nan - val_accuracy: 0.5963 - 13s/epoch - 107ms/step\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 46: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 2.0381e-04 - accuracy: 0.7194 - val_loss: nan - val_accuracy: 0.5897 - 14s/epoch - 114ms/step\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 47: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 2.0335e-04 - accuracy: 0.7115 - val_loss: nan - val_accuracy: 0.5000 - 13s/epoch - 112ms/step\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.9893e-04 - accuracy: 0.7213 - val_loss: nan - val_accuracy: 0.5434 - 14s/epoch - 115ms/step\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 49: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.9756e-04 - accuracy: 0.7297 - val_loss: nan - val_accuracy: 0.5699 - 13s/epoch - 111ms/step\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.9750e-04 - accuracy: 0.7230 - val_loss: nan - val_accuracy: 0.7676 - 13s/epoch - 107ms/step\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 51: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 12s - loss: 1.9301e-04 - accuracy: 0.7331 - val_loss: nan - val_accuracy: 0.4735 - 12s/epoch - 102ms/step\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.9660e-04 - accuracy: 0.7164 - val_loss: nan - val_accuracy: 0.5404 - 13s/epoch - 111ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.9084e-04 - accuracy: 0.7355 - val_loss: nan - val_accuracy: 0.6257 - 13s/epoch - 112ms/step\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 54: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.8879e-04 - accuracy: 0.7461 - val_loss: nan - val_accuracy: 0.6993 - 13s/epoch - 112ms/step\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.8514e-04 - accuracy: 0.7456 - val_loss: 1049285327567271577949879905812480.0000 - val_accuracy: 0.6956 - 14s/epoch - 113ms/step\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 56: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.8516e-04 - accuracy: 0.7431 - val_loss: nan - val_accuracy: 0.6904 - 14s/epoch - 116ms/step\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 57: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.8211e-04 - accuracy: 0.7534 - val_loss: 7956690957354945476144249438208.0000 - val_accuracy: 0.7676 - 14s/epoch - 113ms/step\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 58: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.7457e-04 - accuracy: 0.7635 - val_loss: nan - val_accuracy: 0.4919 - 14s/epoch - 119ms/step\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 59: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.7148e-04 - accuracy: 0.7740 - val_loss: 2790115373807853443982886168428544.0000 - val_accuracy: 0.6728 - 13s/epoch - 111ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.6840e-04 - accuracy: 0.7833 - val_loss: 11358025719289582968769609728.0000 - val_accuracy: 0.7868 - 13s/epoch - 110ms/step\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 61: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 12s - loss: 1.6509e-04 - accuracy: 0.7904 - val_loss: nan - val_accuracy: 0.6515 - 12s/epoch - 101ms/step\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 62: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.6089e-04 - accuracy: 0.7922 - val_loss: 18735842446992169848853851099103232.0000 - val_accuracy: 0.6868 - 13s/epoch - 111ms/step\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 63: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.5721e-04 - accuracy: 0.8015 - val_loss: nan - val_accuracy: 0.6706 - 13s/epoch - 112ms/step\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 64: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.5356e-04 - accuracy: 0.8083 - val_loss: nan - val_accuracy: 0.7066 - 13s/epoch - 111ms/step\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.4863e-04 - accuracy: 0.8208 - val_loss: nan - val_accuracy: 0.4853 - 13s/epoch - 111ms/step\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 66: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 14s - loss: 1.4857e-04 - accuracy: 0.8154 - val_loss: 1505667375907997916145385472.0000 - val_accuracy: 0.6904 - 14s/epoch - 113ms/step\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 67: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.4010e-04 - accuracy: 0.8294 - val_loss: 1390769116855057754935248551936.0000 - val_accuracy: 0.7088 - 13s/epoch - 109ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 68: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.3965e-04 - accuracy: 0.8245 - val_loss: nan - val_accuracy: 0.2147 - 13s/epoch - 109ms/step\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 69: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 12s - loss: 1.3706e-04 - accuracy: 0.8409 - val_loss: nan - val_accuracy: 0.2147 - 12s/epoch - 103ms/step\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.3665e-04 - accuracy: 0.8375 - val_loss: 30834011726209630383112192.0000 - val_accuracy: 0.7500 - 13s/epoch - 109ms/step\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 71: val_loss did not improve from 83753235104626255069184.00000\n",
            "120/120 - 13s - loss: 1.2624e-04 - accuracy: 0.8529 - val_loss: nan - val_accuracy: 0.6559 - 13s/epoch - 109ms/step\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 72: val_loss improved from 83753235104626255069184.00000 to 53076497868430875033600.00000, saving model to /tmp/checkpoint.h5\n",
            "120/120 - 13s - loss: 1.2476e-04 - accuracy: 0.8512 - val_loss: 53076497868430875033600.0000 - val_accuracy: 0.7206 - 13s/epoch - 112ms/step\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 73: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 1.2283e-04 - accuracy: 0.8473 - val_loss: nan - val_accuracy: 0.7265 - 13s/epoch - 112ms/step\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 74: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 15s - loss: 1.2304e-04 - accuracy: 0.8522 - val_loss: nan - val_accuracy: 0.3801 - 15s/epoch - 121ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 18s - loss: 1.2098e-04 - accuracy: 0.8556 - val_loss: 2746890840426145463614370897461248.0000 - val_accuracy: 0.7243 - 18s/epoch - 149ms/step\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 76: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 1.2342e-04 - accuracy: 0.8652 - val_loss: nan - val_accuracy: 0.6147 - 14s/epoch - 119ms/step\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 77: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 1.1111e-04 - accuracy: 0.8664 - val_loss: 2575737898216890705117184.0000 - val_accuracy: 0.7794 - 14s/epoch - 113ms/step\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 78: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 1.1095e-04 - accuracy: 0.8733 - val_loss: nan - val_accuracy: 0.6426 - 13s/epoch - 108ms/step\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 79: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 12s - loss: 1.0341e-04 - accuracy: 0.8821 - val_loss: nan - val_accuracy: 0.4941 - 12s/epoch - 101ms/step\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 1.1143e-04 - accuracy: 0.8716 - val_loss: nan - val_accuracy: 0.6559 - 13s/epoch - 112ms/step\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 81: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 1.0073e-04 - accuracy: 0.8860 - val_loss: nan - val_accuracy: 0.7346 - 14s/epoch - 113ms/step\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 82: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 1.0233e-04 - accuracy: 0.8836 - val_loss: nan - val_accuracy: 0.7250 - 13s/epoch - 111ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 83: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 1.0248e-04 - accuracy: 0.8846 - val_loss: nan - val_accuracy: 0.2147 - 13s/epoch - 111ms/step\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 84: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 15s - loss: 1.0111e-04 - accuracy: 0.8824 - val_loss: 971533665446591724442852786176.0000 - val_accuracy: 0.7309 - 15s/epoch - 122ms/step\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 9.8509e-05 - accuracy: 0.8882 - val_loss: 3702967288542005394938741653504.0000 - val_accuracy: 0.7779 - 14s/epoch - 115ms/step\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 86: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 12s - loss: 9.4857e-05 - accuracy: 0.8949 - val_loss: nan - val_accuracy: 0.5654 - 12s/epoch - 104ms/step\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 87: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 12s - loss: 8.8719e-05 - accuracy: 0.9069 - val_loss: nan - val_accuracy: 0.2147 - 12s/epoch - 103ms/step\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 88: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 8.9532e-05 - accuracy: 0.9000 - val_loss: 400054521319896190038679742316544.0000 - val_accuracy: 0.6721 - 14s/epoch - 113ms/step\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 89: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 9.1116e-05 - accuracy: 0.8956 - val_loss: nan - val_accuracy: 0.6654 - 14s/epoch - 113ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 8.4776e-05 - accuracy: 0.9105 - val_loss: nan - val_accuracy: 0.7118 - 14s/epoch - 113ms/step\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 91: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 8.5100e-05 - accuracy: 0.9142 - val_loss: nan - val_accuracy: 0.7037 - 14s/epoch - 116ms/step\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 92: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 8.6082e-05 - accuracy: 0.9098 - val_loss: 149558942155844039793967104.0000 - val_accuracy: 0.7096 - 14s/epoch - 118ms/step\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 93: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 8.5284e-05 - accuracy: 0.9076 - val_loss: nan - val_accuracy: 0.7360 - 13s/epoch - 112ms/step\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 94: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 12s - loss: 8.6372e-05 - accuracy: 0.9022 - val_loss: nan - val_accuracy: 0.2147 - 12s/epoch - 103ms/step\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 8.2061e-05 - accuracy: 0.9132 - val_loss: 39289530613746786219272005746688.0000 - val_accuracy: 0.7088 - 13s/epoch - 108ms/step\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 96: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 7.7125e-05 - accuracy: 0.9184 - val_loss: nan - val_accuracy: 0.7404 - 14s/epoch - 113ms/step\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 97: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 8.2570e-05 - accuracy: 0.9100 - val_loss: nan - val_accuracy: 0.5272 - 14s/epoch - 115ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 98: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 7.5797e-05 - accuracy: 0.9189 - val_loss: nan - val_accuracy: 0.2147 - 14s/epoch - 114ms/step\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 99: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 13s - loss: 6.9106e-05 - accuracy: 0.9262 - val_loss: nan - val_accuracy: 0.6941 - 13s/epoch - 109ms/step\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: val_loss did not improve from 53076497868430875033600.00000\n",
            "120/120 - 14s - loss: 7.2682e-05 - accuracy: 0.9248 - val_loss: nan - val_accuracy: 0.6882 - 14s/epoch - 115ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy = model.evaluate(X_valid, y_valid, verbose=0)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bImtuT8cuguQ",
        "outputId": "6bccb17a-1203-4673-fbe0-8e64d134eefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 74.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.reshape(test_data_list, (-1, 1, test_data_list.shape[2], test_data_list.shape[3]))\n",
        "\n",
        "\n",
        "# Ensure Y_test has the correct number of samples\n",
        "Y_test = Y_train_valid[:X_test.shape[0]]\n",
        "\n",
        "# Convert to categorical\n",
        "Y_test_cat = to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Print shapes for diagnostics\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"Y_test shape: {Y_test.shape}\")\n",
        "print(f\"Y_test_cat shape: {Y_test_cat.shape}\")\n",
        "\n",
        "# Get the predicted probabilities for the test set\n",
        "Y_pred_prob = model.predict(X_test)\n",
        "if np.any(np.isnan(Y_pred_prob)):\n",
        "    print(\"Warning: NaN values found in predictions. Investigate model or data.\")\n",
        "    # Handle NaNs (e.g., replace with a default value)\n",
        "    Y_pred_prob = np.nan_to_num(Y_pred_prob)\n",
        "# Ensure Y_pred_prob has the correct shape\n",
        "if Y_pred_prob.shape[1] == 1 and Y_pred_prob.shape[0] == X_test.shape[0]:\n",
        "    # Assuming the model is not outputting the probabilities correctly\n",
        "    # Recalculate or reshape as needed\n",
        "    Y_pred_prob = np.tile(Y_pred_prob, (1, 4))\n",
        "if Y_pred_prob.shape[1] == 2:\n",
        "    Y_pred_prob_temp = np.zeros((Y_pred_prob.shape[0], 4))\n",
        "    Y_pred_prob_temp[:, :2] = Y_pred_prob\n",
        "    Y_pred_prob_temp[:, 2:] = 1 - Y_pred_prob\n",
        "    Y_pred_prob = Y_pred_prob_temp\n",
        "\n",
        "# Print the prediction shape for diagnostics\n",
        "print(f\"Y_pred_prob shape: {Y_pred_prob.shape}\")\n",
        "\n",
        "# Ensure the number of samples match\n",
        "assert X_test.shape[0] == Y_test.shape[0] == Y_pred_prob.shape[0], \"Number of samples must match\"\n",
        "\n",
        "# Initialize plot\n",
        "plt.figure()\n",
        "\n",
        "# Calculate ROC curve and AUC for each class\n",
        "for i in range(4):\n",
        "    fpr, tpr, _ = roc_curve(Y_test_cat[:, i], Y_pred_prob[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal line for no-skill classifier\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "\n",
        "# Formatting plot\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9OGbTd8h-sq",
        "outputId": "d8b1639f-c4bb-46e3-b6f8-cc503e27326c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (3400, 1, 56, 140)\n",
            "Y_test shape: (3400,)\n",
            "Y_test_cat shape: (3400, 4)\n",
            "107/107 [==============================] - 3s 24ms/step\n",
            "Warning: NaN values found in predictions. Investigate model or data.\n",
            "Y_pred_prob shape: (3400, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation complete\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a5mKA1bn8qMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subj, trial, channel, sample = train_data_list.shape\n",
        "X_train_valid = np.reshape(train_data_list, (-1, 1, channel, sample))\n",
        "X_test = np.reshape(test_data_list, (-1, 1, channel, sample))\n",
        "\n",
        "Y_train_valid = pd.read_csv('/content/drive/MyDrive/TrainLabels.csv')['Prediction'].values\n",
        "split_thres = int(subj * trial * 0.25)\n",
        "X_train, X_valid = X_train_valid[split_thres:, :], X_train_valid[:split_thres, :]\n",
        "Y_train, Y_valid = Y_train_valid[split_thres:], Y_train_valid[:split_thres]\n",
        "\n",
        "print('training data shape: ' + str(X_train.shape))\n",
        "print('validation data shape: ' + str(X_valid.shape))\n",
        "print('testing data shape: ' + str(X_test.shape))\n",
        "print(Y_train.shape, Y_valid.shape)"
      ],
      "metadata": {
        "id": "xUNp_nU7_tSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501eddd5-fa2c-49a6-d249-df6a8e39bdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data shape: (4080, 1, 56, 140)\n",
            "validation data shape: (1360, 1, 56, 140)\n",
            "testing data shape: (3400, 1, 56, 140)\n",
            "(4080,) (1360,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your labels are in the range [0, 3] for 4 classes\n",
        "Y_train = to_categorical(Y_train, num_classes=4)\n",
        "Y_valid = to_categorical(Y_valid, num_classes=4)\n",
        "class_weights = {i: 1 / np.sum(Y_train[:, i] == 1) for i in range(4)}\n",
        "model = EEGNet(nb_classes=4, Chans=channel, Samples=sample)\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.keras', verbose=1, save_best_only=True)\n",
        "\n",
        "fittedModel = model.fit(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=2,\n",
        "    validation_data=(X_valid, Y_valid),\n",
        "    callbacks=[checkpointer],\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "id": "Fa4ogRaEwkVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "5ace7d19-3323-45c1-93e2-fd63dc040eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-a8d389dcf5af>:4: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  class_weights = {i: 1 / np.sum(Y_train[:, i] == 1) for i in range(4)}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"depthwise_conv2d_7\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 56 from 1 for '{{node depthwise_conv2d_7/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d_7/depthwise/ReadVariableOp)' with input shapes: [?,1,56,8], [56,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d_7\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 56, 8), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a8d389dcf5af>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-fd9649b1b637>\u001b[0m in \u001b[0;36mEEGNet\u001b[0;34m(nb_classes, Chans, Samples, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                    use_bias = False)(input1)\n\u001b[1;32m     16\u001b[0m     \u001b[0mblock1\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                    \u001b[0mdepth_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                    \u001b[0mdepthwise_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mdepthwise_conv2d\u001b[0;34m(x, depthwise_kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   6462\u001b[0m         \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6464\u001b[0;31m     x = tf.nn.depthwise_conv2d(\n\u001b[0m\u001b[1;32m   6465\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6466\u001b[0m         \u001b[0mdepthwise_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"depthwise_conv2d_7\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 56 from 1 for '{{node depthwise_conv2d_7/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d_7/depthwise/ReadVariableOp)' with input shapes: [?,1,56,8], [56,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d_7\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 56, 8), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure data is in correct format (batch_size, channels, height, width)\n",
        "X_train = np.transpose(X_train, (0, 3, 1, 2))  # (batch_size, channels, height, width)\n",
        "X_valid = np.transpose(X_valid, (0, 3, 1, 2))  # (batch_size, channels, height, width)\n",
        "X_test = np.transpose(X_test, (0, 3, 1, 2))    # (batch_size, channels, height, width)\n"
      ],
      "metadata": {
        "id": "Oxf5GXmtAm4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = EEGNet(nb_classes=4, Chans=channel, Samples=sample)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.keras', verbose=1, save_best_only=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FGDkh4E_9sV1",
        "outputId": "38a0dc2f-d0ba-4347-de0d-74047d73b02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"depthwise_conv2d_8\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 56 from 1 for '{{node depthwise_conv2d_8/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d_8/depthwise/ReadVariableOp)' with input shapes: [?,1,56,8], [56,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d_8\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 56, 8), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-17c50e0db720>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/checkpoint.keras'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-fd9649b1b637>\u001b[0m in \u001b[0;36mEEGNet\u001b[0;34m(nb_classes, Chans, Samples, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                    use_bias = False)(input1)\n\u001b[1;32m     16\u001b[0m     \u001b[0mblock1\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                    \u001b[0mdepth_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                    \u001b[0mdepthwise_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mdepthwise_conv2d\u001b[0;34m(x, depthwise_kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   6462\u001b[0m         \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6464\u001b[0;31m     x = tf.nn.depthwise_conv2d(\n\u001b[0m\u001b[1;32m   6465\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6466\u001b[0m         \u001b[0mdepthwise_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"depthwise_conv2d_8\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 56 from 1 for '{{node depthwise_conv2d_8/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d_8/depthwise/ReadVariableOp)' with input shapes: [?,1,56,8], [56,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d_8\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 56, 8), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXPCMBoH_U70",
        "outputId": "eaab25df-5531-43b2-c07d-eae536287541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4080, 1, 56, 140) (1360, 1, 56, 140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Encode target labels\n",
        "Y_train_cat = to_categorical(Y_train, num_classes=4)\n",
        "Y_valid_cat = to_categorical(Y_valid, num_classes=4)\n",
        "\n",
        "# Ensure the shape of Y_train_cat and Y_valid_cat\n",
        "print('Y_train_cat shape:', Y_train_cat.shape)  # Should be (4080, 4)\n",
        "print('Y_valid_cat shape:', Y_valid_cat.shape)  # Should be (1360, 4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI-OHjuSByn9",
        "outputId": "dff0bd66-bcf1-49b7-dc00-d439bbd371c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_train_cat shape: (4080, 4, 4)\n",
            "Y_valid_cat shape: (1360, 4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure data is in correct format (batch_size, height, width, channels)\n",
        "X_train = np.transpose(X_train, (0, 2, 3, 1))  # (batch_size, height, width, channels)\n",
        "X_valid = np.transpose(X_valid, (0, 2, 3, 1))  # (batch_size, height, width, channels)\n",
        "X_test = np.transpose(X_test, (0, 2, 3, 1))    # (batch_size, height, width, channels)\n",
        "\n"
      ],
      "metadata": {
        "id": "R52JRDGeCbFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHb0lL8LDEuH",
        "outputId": "8c58117c-cb7e-4743-f903-a2672f8324a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4080, 56, 140, 1) (1360, 56, 140, 1) (3400, 56, 140, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fittedModel = model.fit(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=2,\n",
        "    validation_data=(X_valid, Y_valid),\n",
        "    callbacks=[checkpointer],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "22Jq6zQZ-wni",
        "outputId": "c38e22c1-8e6d-4ce0-f073-91f5ad991287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 1, 56, 140), found shape=(None, 56, 140, 1)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-2b767a3b8217>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fittedModel = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 1, 56, 140), found shape=(None, 56, 140, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Ensure data is in NHWC format\n",
        "#X_train = np.transpose(X_train, (0, 2, 3, 1))\n",
        "#X_valid = np.transpose(X_valid, (0, 2, 3, 1))\n",
        "#X_test = np.transpose(X_test, (0, 2, 3, 1))\n",
        "\n",
        "# One-Hot Encode Your Labels\n",
        "Y_train = to_categorical(Y_train, num_classes=4)\n",
        "Y_valid = to_categorical(Y_valid, num_classes=4)\n",
        "\n",
        "# Adjust Class Weights\n",
        "class_weights = {}\n",
        "for i in range(4):\n",
        "    count = np.sum(Y_train[:, i] == 1)\n",
        "    if count > 0:\n",
        "        class_weights[i] = 1 / count\n",
        "    else:\n",
        "        class_weights[i] = 1.0\n",
        "\n",
        "# Define and Compile the Model\n",
        "model = EEGNet(nb_classes=4, Chans=channel, Samples=sample)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define ModelCheckpoint Callback\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.keras', verbose=1, save_best_only=True)\n",
        "\n",
        "# Train the Model\n",
        "fittedModel = model.fit(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=2,\n",
        "    validation_data=(X_valid, Y_valid),\n",
        "    callbacks=[checkpointer],\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ljf50cvz8mgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Y_train_cat = to_categorical(Y_train, num_classes=4)\n",
        "Y_valid_cat = to_categorical(Y_valid, num_classes=4)\n",
        "\n",
        "# Flatten the training data for StratifiedKFold\n",
        "n_samples = X_train.shape[0]\n",
        "X_train_flat = X_train.reshape(n_samples, -1)\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "n_splits = 2\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Placeholder for storing fold results\n",
        "fold_accuracies = []\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(skf.split(X_train_flat, Y_train)):\n",
        "    print(f\"Training fold {fold + 1}/{n_splits}...\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
        "    Y_train_fold, Y_valid_fold = Y_train_cat[train_index], Y_train_cat[valid_index]\n",
        "    X_train_fold = np.transpose(X_train_fold, (0, 3, 1, 2))\n",
        "    X_valid_fold = np.transpose(X_valid_fold, (0, 3, 1, 2))\n",
        "\n",
        "    # Define the EEGNet model\n",
        "    model = EEGNet(nb_classes=4, Chans=channel, Samples=sample)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Define the ModelCheckpoint callback\n",
        "    checkpointer = ModelCheckpoint(filepath=f'/tmp/checkpoint_fold{fold+1}.keras', verbose=1, save_best_only=True)\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = {i: 1 / np.sum(Y_train == i) for i in range(4)}\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(\n",
        "        X_train_fold, Y_train_fold,\n",
        "        batch_size=32,\n",
        "        epochs=1,\n",
        "        verbose=2,\n",
        "        validation_data=(X_valid_fold, Y_valid_fold),\n",
        "        callbacks=[checkpointer],\n",
        "        class_weight=class_weights\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy = model.evaluate(X_valid_fold, Y_valid_fold, verbose=0)\n",
        "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate average accuracy across all folds\n",
        "average_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"Average Accuracy across {n_splits} folds: {average_accuracy}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "Y_test_cat = to_categorical(Y_test, num_classes=4)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test_cat, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Optionally, print summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "sU4JTwE-8uRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}